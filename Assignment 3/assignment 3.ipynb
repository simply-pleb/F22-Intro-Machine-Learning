{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhJqZQPHUiHR"
      },
      "source": [
        "# Bonus assignement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DcXvcAkUiHT"
      },
      "source": [
        "## Instructions\n",
        "- Your submission should be the `.ipynb` file with your name,\n",
        "  like `FirstNameLastName.ipynb`. It should include the answers to the questions in\n",
        "  markdown cells.\n",
        "- You are expected to follow the best practices for code writing and model\n",
        "training. Poor coding style will be penalized.\n",
        "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
        "Plagiarism in the code will result in failing. If you use code from the\n",
        "internet, cite it. \n",
        "- Read each instruction carefully and provide complete answers to each question/task\n",
        "- You are allowed to use Keras or Pytorch \n",
        "\n",
        "> **_NOTE:_**  Write your email address in the cell below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7be7FDTUiHW"
      },
      "source": [
        "*Your email address here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3U93mOXUiHZ"
      },
      "source": [
        "### I- Open questions (3 points)\n",
        "\n",
        "Read [this article](https://link.springer.com/referenceworkentry/10.1007/978-0-387-73003-5_304) and answer the following questions:\n",
        "\n",
        "1. What is incremental learning?\n",
        "    - incremental learning is a machine learning paradigm which aims at learning to train a model \"incrementally\". This is contrasted with a regular approach of training on one big dataset.\n",
        "    - it has several advantages compared to traditional technics. The advantages are:\n",
        "      1. It does not require a sufficient training set before learning\n",
        "      1. It can continuously learn to improve when the system is running\n",
        "      1. It can adapt to changes of the target concept\n",
        "      1. It requires less computation and storage resources than learning from scratch\n",
        "      1. It naturally matches the applications depending on time series \n",
        "\n",
        "2. Why is it important for us to create neural networks that would someday be able to learn incrementally?\n",
        "    - Previously in machine learning it was assumed that training all data on one big dataset was sufficient to train a good model\n",
        "    - \"Unfortunately, many real-world applications cannot match this ideal case, such as in dynamic control systems, web mining, and time series analysis, where the training examples are often fed to the learning algorithms over time, i.e., the learning process is incremental\"\n",
        "\n",
        "3. What is catastrophic forgetting?\n",
        "     - catastrophic forgetting occurs in incrementally learned object detection neural networks when we for example train the model to identify cats with 99% accuracy. After getting good results for cats, we train that model to recognize dogs. As a result, our model loses the ability to identify cats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJp6zS46UiHa"
      },
      "source": [
        "### II- Train simple CNN model for digit classification (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5LHU9dCUiHc"
      },
      "source": [
        "Instructions:\n",
        "- Load MNIST dataset and split it in **Tr**ainning (`Tr`) and **Te**ting set (`Te`), 80% and 20% respectively.\n",
        "- Train a simple CNN for digit classification on the training set. \n",
        "- After fine tuning your CNN, evaluate the `overall` and the `class-wise` performances on `Te`. \n",
        ">**NOTE:** For the class-wise performance, you should plot (e.g., bar plots) the performance of your model on each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ec_wvJi7h1_u"
      },
      "outputs": [],
      "source": [
        "# code from https://keras.io/examples/vision/mnist_convnet/\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "9oXMtXljUpgO"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "X_org = np.append(X_train, X_test, axis=0)\n",
        "y_org = np.append(y_train, y_test, axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_org, y_org, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_image(X):\n",
        "  # Scale images to the [0, 1] range\n",
        "  X = X.astype(\"float32\") / 255\n",
        "  # Make sure images have shape (28, 28, 1)\n",
        "  X = np.expand_dims(X, -1)\n",
        "  \n",
        "  return X\n",
        "\n",
        "X_train = scale_image(X_train)\n",
        "X_test = scale_image(X_test)\n",
        "# X_train = X_train.astype(\"float32\") / 255\n",
        "# X_test = X_test.astype(\"float32\") / 255\n",
        "# X_train = np.expand_dims(X_train, -1)\n",
        "# X_test = np.expand_dims(X_test, -1)\n",
        "print(\"x_train shape:\", X_train.shape)\n",
        "print(X_train.shape[0], \"train samples\")\n",
        "print(X_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LbfUepNdQFw",
        "outputId": "b3954c44-98bd-4e7f-e487-a057e2d28e2d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (56000, 28, 28, 1)\n",
            "56000 train samples\n",
            "14000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WknTOIdfhyXu",
        "outputId": "e2e6c189-7a8b-4324-8e1e-3dbfbe6e624b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyj_a1eFhv7H",
        "outputId": "8d8d304a-c0eb-4969-eda2-ce9d693363db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "394/394 [==============================] - 40s 99ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0254 - val_accuracy: 0.9912\n",
            "Epoch 2/15\n",
            "394/394 [==============================] - 39s 99ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.0264 - val_accuracy: 0.9912\n",
            "Epoch 3/15\n",
            "394/394 [==============================] - 39s 98ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.0242 - val_accuracy: 0.9921\n",
            "Epoch 4/15\n",
            "394/394 [==============================] - 39s 99ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0267 - val_accuracy: 0.9914\n",
            "Epoch 5/15\n",
            "394/394 [==============================] - 39s 99ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0217 - val_accuracy: 0.9927\n",
            "Epoch 6/15\n",
            "394/394 [==============================] - 40s 102ms/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.0214 - val_accuracy: 0.9939\n",
            "Epoch 7/15\n",
            "394/394 [==============================] - 38s 97ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0222 - val_accuracy: 0.9936\n",
            "Epoch 8/15\n",
            "394/394 [==============================] - 39s 98ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0227 - val_accuracy: 0.9932\n",
            "Epoch 9/15\n",
            "394/394 [==============================] - 38s 98ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0236 - val_accuracy: 0.9916\n",
            "Epoch 10/15\n",
            "394/394 [==============================] - 39s 99ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0221 - val_accuracy: 0.9937\n",
            "Epoch 11/15\n",
            "394/394 [==============================] - 40s 101ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0226 - val_accuracy: 0.9937\n",
            "Epoch 12/15\n",
            "394/394 [==============================] - 38s 97ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
            "Epoch 13/15\n",
            "394/394 [==============================] - 39s 98ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
            "Epoch 14/15\n",
            "394/394 [==============================] - 39s 98ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.0197 - val_accuracy: 0.9941\n",
            "Epoch 15/15\n",
            "394/394 [==============================] - 39s 99ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0214 - val_accuracy: 0.9932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9624b47b20>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seperate_classes(X, y):\n",
        "  # print(X.shape)\n",
        "  classes_list_X = [[] for _ in range(10)]\n",
        "  classes_list_y = [[] for _ in range(10)]\n",
        "  # for i in range(len(y)):\n",
        "  # print(classes_list_X[4])\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    for j in range(len(y[i])):\n",
        "      if y[i][j] > 0:\n",
        "          # print(j)\n",
        "          classes_list_X[j].append(X[i])\n",
        "          classes_list_y[j].append(y[i])\n",
        "          break\n",
        "\n",
        "  # print('len', len(classes_list_X[1]))\n",
        "  classes_list_X = [np.array(classes_list_X[i]) for i in range(len(classes_list_X))]\n",
        "  classes_list_y = [np.array(classes_list_y[i]) for i in range(len(classes_list_y))]\n",
        "  # print(classes_list_X[5].shape)\n",
        "\n",
        "  return classes_list_X, classes_list_y"
      ],
      "metadata": {
        "id": "rRgb0tmuILp0"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_classwise, y_test_classwise = seperate_classes(X_test, y_test)\n",
        "X_train_classwise, y_train_classwise = seperate_classes(X_train, y_train)"
      ],
      "metadata": {
        "id": "kH3dnUk9Pb_4"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytQQhZdUhtP2",
        "outputId": "44dff6d6-f013-4019-c3bc-0d6be3418323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.03200620412826538\n",
            "Test accuracy: 0.990928590297699\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "loss = []\n",
        "for i in range(10):\n",
        "  score = model.evaluate(X_test_classwise[i], y_test_classwise[i], verbose=0)\n",
        "  print(\"Recognizing digit\", i)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "  loss.append(score[0])\n",
        "  accuracy.append(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFRO8nuyn1cF",
        "outputId": "95cce363-709f-43bf-dc31-c9bbc091eff8"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognizing digit 0\n",
            "Test loss: 0.020038694143295288\n",
            "Test accuracy: 0.9949531555175781\n",
            "Recognizing digit 1\n",
            "Test loss: 0.011834449134767056\n",
            "Test accuracy: 0.9962025284767151\n",
            "Recognizing digit 2\n",
            "Test loss: 0.037714019417762756\n",
            "Test accuracy: 0.987525999546051\n",
            "Recognizing digit 3\n",
            "Test loss: 0.03702180087566376\n",
            "Test accuracy: 0.9832752346992493\n",
            "Recognizing digit 4\n",
            "Test loss: 0.0477629154920578\n",
            "Test accuracy: 0.9933333396911621\n",
            "Recognizing digit 5\n",
            "Test loss: 0.03765318915247917\n",
            "Test accuracy: 0.9902518391609192\n",
            "Recognizing digit 6\n",
            "Test loss: 0.02647768147289753\n",
            "Test accuracy: 0.9949531555175781\n",
            "Recognizing digit 7\n",
            "Test loss: 0.01884615421295166\n",
            "Test accuracy: 0.9945130348205566\n",
            "Recognizing digit 8\n",
            "Test loss: 0.03735807165503502\n",
            "Test accuracy: 0.9853801131248474\n",
            "Recognizing digit 9\n",
            "Test loss: 0.04989571496844292\n",
            "Test accuracy: 0.9882439374923706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.bar([i for i in range(10)], accuracy)\n",
        "ax.bar([i for i in range(10)], loss)\n",
        "\n",
        "ax.legend(labels=['Accuracy', 'Loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "EKT71AWupQqz",
        "outputId": "7c114c3a-9c0d-4a4b-afab-a6d5900c83a1"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLfWheW4UiHc"
      },
      "source": [
        "### III- Create different tasks from the MNIST dataset (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K07-xCoZUiHd"
      },
      "source": [
        "Split `Tr` into 3 datasets (tasks) according to the following distribution.\n",
        "\n",
        "- Task 1 contains digits of classes 0, 1, and 2. \n",
        "- Task 2 contains classes 3, 4, and 5. \n",
        "- Task 3 contains classes 6, 7, 8, and 9.\n",
        " \n",
        "*The following picture showcases the general scheme*\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1vdDgdN9BGQ2Jl3Yg4YiPvfb5fcAeJZJ-' style=\"width:500px;\"> \n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_org = scale_image(X_org)\n",
        "y_org = keras.utils.to_categorical(y_org, num_classes)"
      ],
      "metadata": {
        "id": "-NCAnEm6vXBX"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "uGG188h1UqnL"
      },
      "outputs": [],
      "source": [
        "X_classwise, y_classwise = seperate_classes(X_org, y_org)\n",
        "\n",
        "X_task1 = np.append(X_classwise[0], X_classwise[1], axis=0)\n",
        "X_task1 = np.append(X_task1, X_classwise[2], axis=0)\n",
        "y_task1 = np.append(y_classwise[0], y_classwise[1], axis=0)\n",
        "y_task1 = np.append(y_task1, y_classwise[2], axis=0)\n",
        "\n",
        "X_task2 = np.append(X_classwise[3], X_classwise[4], axis=0)\n",
        "X_task2 = np.append(X_task2, X_classwise[5], axis=0)\n",
        "y_task2 = np.append(y_classwise[3], y_classwise[4], axis=0)\n",
        "y_task2 = np.append(y_task2, y_classwise[5], axis=0)\n",
        "\n",
        "X_task3 = np.append(X_classwise[6], X_classwise[7], axis=0)\n",
        "X_task3 = np.append(X_task3, X_classwise[8], axis=0)\n",
        "X_task3 = np.append(X_task3, X_classwise[9], axis=0)\n",
        "y_task3 = np.append(y_classwise[6], y_classwise[7], axis=0)\n",
        "y_task3 = np.append(y_task3, y_classwise[8], axis=0)\n",
        "y_task3 = np.append(y_task3, y_classwise[9], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phEpEVnXzvGP",
        "outputId": "86c2b4c4-c9fa-4622-b8da-1c13ff22e7ff"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFlx3tv8z9Nk",
        "outputId": "a8786eda-33a3-402a-9859-beb21a2eae68"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7-tOMvqz_2T",
        "outputId": "5580246f-1fe8-485a-ed03-41f2c1644eae"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw42UsNiUiHe"
      },
      "source": [
        "### IV- Class-incremental learning implementation (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRPUB9dbUiHg"
      },
      "source": [
        "Using the different tasks (datasets) you created previously, implement a CNN for class incremental learning according to the following instructions. \n",
        "- The neural network architecture is not given, choose and tune your architecture following DNNs best practices. Similarly for the training no hyperparameters are given to you, you should choose them and justify your choice. Hyperparameter tuning is not mandatory but doing it would be a plus.\n",
        "- Your network should have shared feature extractor (shared layers) part and separate classifier head (e.g., fully connected layers) for each task (see the figure below).\n",
        "- When training on a new task, the shared layers part will get updated along with the head of the current task. \n",
        "- After training each task (Task 1 & 2), evaluate (and plot) the performances of the current and the previous tasks on `Te`.\n",
        "    - Once the training on the last task is complete, test the model on `Te` and compare the performance of the network with the CNN trained in II, i.e., plot the `overall` and the `class-wise` performances for classical learning and incremental learning.\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1HfwcMP7jGoJnYEMu7jDqloQNogEZsjrJ'  style=\"width:250px;\"> \n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i forgor 🥹"
      ],
      "metadata": {
        "id": "CrQejycL4ChY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGXUVc2zUiHi"
      },
      "source": [
        "### V- Report (2 points)\n",
        "Write a short report on the results you got and what you learned from this activity"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}